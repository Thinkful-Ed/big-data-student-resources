{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing/Predicting Sentiment From Amazon Reviews\n",
    "\n",
    "For this exercise, let's go back to the sentiment analysis we did earlier in the course - specifically, the Amazon reviews dataset.\n",
    "\n",
    "It's important to start with a clear goal in mind. In this case, we'd like to determine if we can __predict whether a review is positive or negative based on the language in the review.__\n",
    "\n",
    "We're going to tackle this problem with Spark - so you'll need to apply the principles you've learned thus far in the context of Spark.\n",
    "\n",
    "Some tips to help you get started:\n",
    "1. Pyspark always needs to point at a running Spark instance. You can do that using a `SparkContext`.\n",
    "2. We're still working in batch mode, so you'll need to load an entire file into memory in order to run any models you build.\n",
    "3. Spark likes to execute models in a pipeline, so remember that when the time comes to set up your model.\n",
    "4. Spark's machine learning algorithms expect numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "\n",
    "# these imports are how we build and manager our data science processes: cleaning data, preparing a model,\n",
    "# executing the model, and evaluating the model.\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a set of constants for clarity and simplicity in managing the notebook.\n",
    "# this allows you to refer back to this cell at any time if you need to either confirm or modify any of these values.\n",
    "\n",
    "DATA_NAME = \"AmznInstantVideo.json\"\n",
    "APP_NAME = \"Sentiment Analysis with Amazon Reviews Exercise\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 4\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we always do is create a `SparkContext`, and then immediately afterward create a `sqlContext` to be able to load and manipulate an RDD/dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've connected to Spark and have a sqlContext ready, it's time to load our data. \n",
    "\n",
    "We assume that you've already checked over some of the data, understand its type, and expected values/lengths before you get here.\n",
    "\n",
    "Luckily this is a simple exercise - this is a JSON file and all we need to do is load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amznInstantVideo = sqlContext.read.json(DATA_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of the dataset, and review the schema so we see what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is 37121 rows by 9 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape is {amznInstantVideo.count():d} rows by {len(amznInstantVideo.columns):d} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amznInstantVideo.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our schema shows that there is hope for our problem. Specifically, there are two columns that look interesting, and potentially a third:\n",
    "\n",
    "* __overall__: this looks like where we're keeping the starred review - on a scale of 1 to 5. We can make a decision on how we want to handle this in our model.\n",
    "* __reviewText__: This looks like it's the actual text of the review - we need to figure out from this whether or not it is positive or negative.\n",
    "* __summary__: This could also be helpful, but we need to understand what it is.\n",
    "\n",
    "Based on this cursory review of the dataset, we can see that we should be able to prepare this data such that we can use a classifier to model the sentiment (positive/negative) of the dataset.\n",
    "\n",
    "There are two data preparation steps we'll need to do before we run our model:\n",
    "1. Decide whether to recode our __overall__ column into a more limited variable - either simply __positive/negative__ or __positive/neutral/negative__\n",
    "2. Convert the text of each review into a numerical vector. Pyspark offers a number of methods to do this - we'll use __Word2Vec__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__------------------------__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get going on our data preparation, let's take a look at the columns we mentioned above.\n",
    "\n",
    "To perform a SQL query on a dataframe, we need to create a `tempTable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amznInstantVideo.registerTempTable('reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|overall|reviewCount|\n",
      "+-------+-----------+\n",
      "|    5.0|      20888|\n",
      "|    4.0|       8445|\n",
      "|    3.0|       4185|\n",
      "|    2.0|       1885|\n",
      "|    1.0|       1718|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select overall, count(overall) as reviewCount from reviews group by overall order by overall desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the reviews are 5-star - so we certainly should recode. For our purposes, we can get closer to a balanced dataset if we recode to >3 is positive, <= 3 is negative. \n",
    "\n",
    "It's a bit of a stretch but a decent first pass.\n",
    "\n",
    "(Later, if you want to improve your classifier's performance, you could apply a resampling method to help balance the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recode the overall score to __positive__ or __negative__\n",
    "* __Positive__: overall > 3\n",
    "* __Negative__: overall <= 3\n",
    "\n",
    "The easiest path to recoding the data in this fashion is to create a new column, from a User Defined Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = UserDefinedFunction(lambda x: 1 if x > 3.0 else -1, IntegerType())\n",
    "\n",
    "amznInstantVideo = amznInstantVideo.withColumn(\"overall_recode\",udf(amznInstantVideo.overall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time let's just make a plot of the two labels - so we can see the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f07df305b70>,\n",
       "  <matplotlib.axis.XTick at 0x7f07df37dac8>],\n",
       " <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAF1CAYAAABBFH8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGnZJREFUeJzt3X/wb3VdJ/DnKy6YrbKAXEkvGKR3a28zG9Z3kX7sjmsbXKwWMzIs9WZsNJNsOlOzYTM7mNqOzqSWpc7QQICrIpklYxTecW1tG3/wxUgFY7n5Y+CGcOWC6FIa9No/vuduH3nfy/3CvZ/7ud/7fTxmznzOeZ33Oed1+AO+T875vD/V3QEAAIBZ37ToBgAAADj8CIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWARg3aqqK6rqtVX176rq1oN43j+tqm3T+s9W1f8+iOf+mar6wME6HwDsy4ZFNwAAi9bdf5HkO/Y3rqpeleQZ3f2i/ZzvnIPRV1WdmuRzSY7u7genc78jyTsOxvkB4JF4sggAB0mt8N9WAI4I/oMGwLpRVc+sqk9U1Veq6t1JvnmqP7uq7pgZ96tVtXMad2tV/VBVbU3ya0l+qqq+WlV/PY3986r6jar6yyQPJPn2qfafv/HS9btV9eWq+puq+qGZHZ+vqv84s/2qqvof0+aHp8/7pmt+38Nfa62q76+qG6Zz31BV3z+z78+r6jVV9ZfTvXygqk48WP88ATiyCYsArAtVdUySP07y9iQnJPmDJD+xl3HfkeSiJP+2u5+Y5Owkn+/uP0vy35O8u7uf0N3fPXPYi5NcmOSJSb6wl8s/K8nfJjkxySVJ3ltVJ6yi7X8/fR43XfMjD+v1hCR/kuTNSZ6U5I1J/qSqnjQz7KeTvDTJk5Mck+RXVnFdABAWAVg3zkxydJLf6u5/7O73JLlhL+MeSvK4JFuq6uju/nx3/+1+zn1Fd9/c3Q929z/uZf/dM9d9d5Jbk/zIAdzLHj+S5Lbufvt07Xcl+ZskPzYz5ve7+/90998nuSbJ6QfhugCsA8IiAOvFU5Ps7O6eqQ1PAbt7R5JXJHlVkrur6uqqeup+zn37fvbv7br7O+dqPDXjPXwhyaaZ7S/OrD+Q5AkH4boArAPCIgDrxZ1JNlVVzdSetreB3f3O7v7BJN+WpJO8fs+ufZx7X/U99nbdv5vW/2+Sb5nZ962P4rx/N/U462lJdu7nOADYL2ERgPXiI0keTPJLVXV0VT0/yRkPH1RV31FVz6mqxyX5hyR/n+Sfpt13JTn1Mcx4+uSZ6/5kkn+d5Lpp301Jzp/2LSU5b+a4XdO1v30f570uyb+qqp+uqg1V9VNJtiR5/6PsDwAGwiIA60J3fz3J85P8bJLdSX4qyXv3MvRxSV6X5EtZeYXzyUleOe37g+nznqr6xKO4/MeSbJ7O+RtJzuvue6Z9/y3J05Pcm+TXk7xzpucHpvF/WVX3VdWZD7une5L8aJJfTnJPkv+a5Ee7+0uPojcA2Kv6xq9QAAAAgCeLAAAA7IWwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGGxYdAOH2oknntinnnrqotsAAABYiBtvvPFL3b1xf+PWXVg89dRTs7y8vOg2AAAAFqKqvrCacV5DBQAAYCAsAgAAMBAWAQAAGMwtLFbVN1fVx6vqr6vq5qr69al+WlV9rKp2VNW7q+qYqf64aXvHtP/UmXO9cqrfWlVnz9S3TrUdVXXxvO4FAABgvZnnk8WvJXlOd393ktOTbK2qM5O8PsmbuvsZSe5NcsE0/oIk9071N03jUlVbkpyf5LuSbE3y1qo6qqqOSvKWJOck2ZLkhdNYAAAADtDcwmKv+Oq0efS0dJLnJHnPVL8yyfOm9XOn7Uz7f6iqaqpf3d1f6+7PJdmR5Ixp2dHdn+3urye5ehoLAADAAZrrdxanJ4A3Jbk7yfYkf5vkvu5+cBpyR5JN0/qmJLcnybT/y0meNFt/2DH7qu+tjwurarmqlnft2nUwbg0AAOCINtew2N0PdffpSU7OypPA75zn9R6hj0u7e6m7lzZu3O9vTwIAAKx7h2Q21O6+L8mHknxfkuOqasO06+QkO6f1nUlOSZJp/79Mcs9s/WHH7KsOAADAAZrnbKgbq+q4af3xSX44yWeyEhrPm4ZtS/K+af3aaTvT/v/Z3T3Vz59mSz0tyeYkH09yQ5LN0+yqx2RlEpxr53U/AAAA68mG/Q95zJ6S5Mpp1tJvSnJNd7+/qm5JcnVVvTbJXyW5bBp/WZK3V9WOJLuzEv7S3TdX1TVJbknyYJKXdfdDSVJVFyW5PslRSS7v7pvneD8AAADrRq08vFs/lpaWenl5edFtAAAALERV3djdS/sbd0i+swgAAMDaMs/XUAEAWC+qFt0BHH7W+FucniwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGMwtLFbVKVX1oaq6papurqqXT/VXVdXOqrppWp47c8wrq2pHVd1aVWfP1LdOtR1VdfFM/bSq+thUf3dVHTOv+wEAAFhP5vlk8cEkv9zdW5KcmeRlVbVl2vem7j59Wq5Lkmnf+Um+K8nWJG+tqqOq6qgkb0lyTpItSV44c57XT+d6RpJ7k1wwx/sBAABYN+YWFrv7zu7+xLT+lSSfSbLpEQ45N8nV3f217v5ckh1JzpiWHd392e7+epKrk5xbVZXkOUneMx1/ZZLnzeduAAAA1pdD8p3Fqjo1yTOTfGwqXVRVn6yqy6vq+Km2KcntM4fdMdX2VX9Skvu6+8GH1fd2/Qurarmqlnft2nUQ7ggAAODINvewWFVPSPKHSV7R3fcneVuSpyc5PcmdSd4w7x66+9LuXurupY0bN877cgAAAGvehnmevKqOzkpQfEd3vzdJuvuumf2/l+T90+bOJKfMHH7yVMs+6vckOa6qNkxPF2fHAwAAcADmORtqJbksyWe6+40z9afMDPvxJJ+e1q9Ncn5VPa6qTkuyOcnHk9yQZPM08+kxWZkE59ru7iQfSnLedPy2JO+b1/0AAACsJ/N8svgDSV6c5FNVddNU+7WszGZ6epJO8vkkv5Ak3X1zVV2T5JaszKT6su5+KEmq6qIk1yc5Ksnl3X3zdL5fTXJ1Vb02yV9lJZwCAABwgGrlAd36sbS01MvLy4tuAwDgyFK16A7g8HOYZq2qurG7l/Y37pDMhgoAAMDaIiwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADOYWFqvqlKr6UFXdUlU3V9XLp/oJVbW9qm6bPo+f6lVVb66qHVX1yar6nplzbZvG31ZV22bq31tVn5qOeXNV1bzuBwAAYD2Z55PFB5P8cndvSXJmkpdV1ZYkFyf5YHdvTvLBaTtJzkmyeVouTPK2ZCVcJrkkybOSnJHkkj0Bcxrz8zPHbZ3j/QAAAKwbcwuL3X1nd39iWv9Kks8k2ZTk3CRXTsOuTPK8af3cJFf1io8mOa6qnpLk7CTbu3t3d9+bZHuSrdO+Y7v7o93dSa6aORcAAAAH4JB8Z7GqTk3yzCQfS3JSd9857fpikpOm9U1Jbp857I6p9kj1O/ZS39v1L6yq5apa3rVr1wHdCwAAwHow97BYVU9I8odJXtHd98/um54I9rx76O5Lu3upu5c2btw478sBAACseXMNi1V1dFaC4ju6+71T+a7pFdJMn3dP9Z1JTpk5/OSp9kj1k/dSBwAA4ADNczbUSnJZks909xtndl2bZM+MptuSvG+m/pJpVtQzk3x5el31+iRnVdXx08Q2ZyW5ftp3f1WdOV3rJTPnAgAA4ABsmOO5fyDJi5N8qqpummq/luR1Sa6pqguSfCHJC6Z91yV5bpIdSR5I8tIk6e7dVfWaJDdM417d3bun9V9MckWSxyf502kBAADgANXK1wbXj6WlpV5eXl50GwAARxY/dw2jwzRrVdWN3b20v3GHZDZUAAAA1hZhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMFhVWKyql1fVsbXisqr6RFWdNe/mAAAAWIzVPln8ue6+P8lZSY5P8uIkr5tbVwAAACzUasNiTZ/PTfL27r55pgYAAMARZrVh8caq+kBWwuL1VfXEJP80v7YAAABYpA2rHHdBktOTfLa7H6iqJyV56fzaAgAAYJFW+2Rxe3d/orvvS5LuvifJm+bXFgAAAIv0iE8Wq+qbk3xLkhOr6vj88/cUj02yac69AQAAsCD7ew31F5K8IslTk9yYfw6L9yf53Tn2BQAAwAI9Yljs7t9O8ttV9V+6+3cOUU8AAAAs2KomuOnu36mq709y6uwx3X3VnPoCAABggVYVFqvq7UmenuSmJA9N5U4iLAIAAByBVvvTGUtJtnR3z7MZAAAADg+r/emMTyf51nk2AgAAwOFjtU8WT0xyS1V9PMnX9hS7+z/NpSsAAAAWarVh8VXzbAIAAIDDy6peQ+3u/7W35ZGOqarLq+ruqvr0TO1VVbWzqm6alufO7HtlVe2oqlur6uyZ+taptqOqLp6pn1ZVH5vq766qYx7drQMAALAvqwqLVfWVqrp/Wv6hqh6qqvv3c9gVSbbupf6m7j59Wq6bzr8lyflJvms65q1VdVRVHZXkLUnOSbIlyQunsUny+ulcz0hyb5ILVnMvAAAA7N9qnyw+sbuP7e5jkzw+yU8keet+jvlwkt2r7OPcJFd399e6+3NJdiQ5Y1p2dPdnu/vrSa5Ocm5VVZLnJHnPdPyVSZ63ymsBAACwH6udDfX/6xV/nOTs/Q7eu4uq6pPTa6rHT7VNSW6fGXPHVNtX/UlJ7uvuBx9W36uqurCqlqtqedeuXY+xbQAAgPVjta+hPn9mOa+qXpfkHx7D9d6W5OlJTk9yZ5I3PIZzPGrdfWl3L3X30saNGw/FJQEAANa01c6G+mMz6w8m+XxWXh19VLr7rj3rVfV7Sd4/be5McsrM0JOnWvZRvyfJcVW1YXq6ODseAACAA7SqsNjdLz0YF6uqp3T3ndPmjyfZM1PqtUneWVVvTPLUJJuTfDxJJdlcVadlJQyen+Snu7ur6kNJzsvK9xi3JXnfwegRAACAVYbFqjo5ye8k+YGp9BdJXt7ddzzCMe9K8uwkJ1bVHUkuSfLsqjo9SWfl6eQvJEl331xV1yS5JStPLl/W3Q9N57koyfVJjkpyeXffPF3iV5NcXVWvTfJXSS5b5T0DAACwH9Xd+x9UtT3JO5O8fSq9KMnPdPcPz7G3uVhaWurl5eVFtwEAcGSpWnQHcPhZRdZahKq6sbuX9jdutbOhbuzu3+/uB6fliiRmigEAADhCrTYs3lNVL6qqo6blRVmZZAYAAIAj0GrD4s8leUGSL2blJy/OS/Kzc+oJAACABVvtT2e8Osm27r43SarqhCS/mZUQCQAAwBFmtU8W/82eoJgk3b07yTPn0xIAAACLttqw+E1VdfyejenJ4mqfSgIAALDGrDbwvSHJR6rqD6btn0zyG/NpCQAAgEVbVVjs7quqajnJc6bS87v7lvm1BQAAwCKt+lXSKRwKiAAAAOvAar+zCAAAwDoiLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMJhbWKyqy6vq7qr69EzthKraXlW3TZ/HT/WqqjdX1Y6q+mRVfc/MMdum8bdV1baZ+vdW1aemY95cVTWvewEAAFhv5vlk8YokWx9WuzjJB7t7c5IPTttJck6SzdNyYZK3JSvhMsklSZ6V5Iwkl+wJmNOYn5857uHXAgAA4DGaW1js7g8n2f2w8rlJrpzWr0zyvJn6Vb3io0mOq6qnJDk7yfbu3t3d9ybZnmTrtO/Y7v5od3eSq2bOBQAAwAE61N9ZPKm775zWv5jkpGl9U5LbZ8bdMdUeqX7HXuoAAAAcBAub4GZ6ItiH4lpVdWFVLVfV8q5duw7FJQEAANa0Qx0W75peIc30efdU35nklJlxJ0+1R6qfvJf6XnX3pd291N1LGzduPOCbAAAAONId6rB4bZI9M5puS/K+mfpLpllRz0zy5el11euTnFVVx08T25yV5Ppp3/1VdeY0C+pLZs4FAADAAdowrxNX1buSPDvJiVV1R1ZmNX1dkmuq6oIkX0jygmn4dUmem2RHkgeSvDRJunt3Vb0myQ3TuFd3955Jc34xKzOuPj7Jn04LAAAAB0GtfHVw/VhaWurl5eVFtwEAcGTxk9cwOkyzVlXd2N1L+xu3sAluAAAAOHwJiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMNiy6ASZVi+4ADi/di+4AAGBd82QRAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAwULCYlV9vqo+VVU3VdXyVDuhqrZX1W3T5/FTvarqzVW1o6o+WVXfM3OebdP426pq2yLuBQAA4Ei0yCeL/6G7T+/upWn74iQf7O7NST44bSfJOUk2T8uFSd6WrITLJJckeVaSM5JcsidgAgAAcGAOp9dQz01y5bR+ZZLnzdSv6hUfTXJcVT0lydlJtnf37u6+N8n2JFsPddMAAABHokWFxU7ygaq6saounGondfed0/oXk5w0rW9KcvvMsXdMtX3VAQAAOEAbFnTdH+zunVX15CTbq+pvZnd2d1dVH6yLTYH0wiR52tOedrBOCwAAcMRayJPF7t45fd6d5I+y8p3Du6bXSzN93j0N35nklJnDT55q+6rv7XqXdvdSdy9t3LjxYN4KAADAEemQh8Wq+hdV9cQ960nOSvLpJNcm2TOj6bYk75vWr03ykmlW1DOTfHl6XfX6JGdV1fHTxDZnTTUAAAAO0CJeQz0pyR9V1Z7rv7O7/6yqbkhyTVVdkOQLSV4wjb8uyXOT7EjyQJKXJkl3766q1yS5YRr36u7efehuAwAA4MhV3Qftq4FrwtLSUi8vLy+6jdFKeAb2WGf/bgJY8/wtA6PD9O+Zqrpx5icM9+lw+ukMAAAADhPCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGAgLAIAADAQFgEAABgIiwAAAAyERQAAAAbCIgAAAANhEQAAgIGwCAAAwEBYBAAAYCAsAgAAMBAWAQAAGAiLAAAADIRFAAAABsIiAAAAA2ERAACAgbAIAADAQFgEAABgICwCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBgzYfFqtpaVbdW1Y6qunjR/QAAABwJ1nRYrKqjkrwlyTlJtiR5YVVtWWxXAAAAa9+aDotJzkiyo7s/291fT3J1knMX3BMAAMCat9bD4qYkt89s3zHVAAAAOAAbFt3AoVBVFya5cNr8alXdush+gFWoOjHJlxbdBgDAY3b4/j3zbasZtNbD4s4kp8xsnzzVvkF3X5rk0kPVFHDgqmq5u5cW3QcAwGO11v+eWeuvod6QZHNVnVZVxyQ5P8m1C+4JAABgzVvTTxa7+8GquijJ9UmOSnJ5d9+84LYAAADWvDUdFpOku69Lct2i+wAOOq+OAwBr3Zr+e6a6e9E9AAAAcJhZ699ZBAAAYA6EReCwU1XfWVUfqaqvVdWvLLofAIBHo6our6q7q+rTi+7lQAiLwOFod5JfSvKbi24EAOAxuCLJ1kU3caCEReCw0913d/cNSf5x0b0AADxa3f3hrPzP7zVNWAQAAGAgLAIAADAQFoHDQlW9rKpumpanLrofAID1bsOiGwBIku5+S5K3LLoPAABWVHcvugeAb1BV35pkOcmxSf4pyVeTbOnu+xfaGADAKlTVu5I8O8mJSe5Kckl3X7bQph4DYREAAICB7ywCAAAwEBYBAAAYCIsAAAAMhEUAAAAGwiIAAAADYREAAICBsAgAAMBAWAQAAGDw/wApmgUOQD6pfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07df31f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    " \n",
    "statuses = amznInstantVideo.groupBy('overall_recode').count().collect()\n",
    "\n",
    "categories = [i[0] for i in statuses]\n",
    "counts = [i[1] for i in statuses]\n",
    " \n",
    "ind = np.array(range(len(categories)))\n",
    "width = 0.35\n",
    "plt.bar(ind, counts, width=width, color='r')\n",
    " \n",
    "plt.ylabel('counts')\n",
    "plt.title('distribution')\n",
    "plt.xticks(ind + width/2., categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to look at the text and encode it into vectors.\n",
    "\n",
    "First, let's take a look at the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+--------------------+\n",
      "|overall|overall_recode|             summary|          reviewText|\n",
      "+-------+--------------+--------------------+--------------------+\n",
      "|    2.0|            -1|A little bit bori...|I had big expecta...|\n",
      "|    5.0|             1|Excellent Grown U...|I highly recommen...|\n",
      "|    1.0|            -1|Way too boring fo...|This one is a rea...|\n",
      "|    4.0|             1|Robson Green is m...|Mysteries are int...|\n",
      "|    5.0|             1|Robson green and ...|This show always ...|\n",
      "|    5.0|             1|I purchased the s...|I discovered this...|\n",
      "|    3.0|            -1|It takes up your ...|It beats watching...|\n",
      "|    3.0|            -1|A reasonable way ...|There are many ep...|\n",
      "|    5.0|             1|           kansas001|This is the best ...|\n",
      "|    3.0|            -1| Entertaining Comedy|Not bad.  Didn't ...|\n",
      "+-------+--------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amznInstantVideo.select(\"overall\", \"overall_recode\", \"summary\", \"reviewText\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the start of this exercise we'll use only the `reviewText` column; later we could even merge the `summary` and `reviewText` to see if it improves the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokenized_text\").transform(amznInstantVideo)\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=300, seed=42, inputCol=\"tokenized_text\", outputCol=\"w2v_vector\").fit(tokenizer)\n",
    "\n",
    "w2vdf=word2Vec.transform(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      " |-- overall_recode: integer (nullable = true)\n",
      " |-- tokenized_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- w2v_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2vdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------+\n",
      "|overall_recode|          reviewText|      tokenized_text|          w2v_vector|\n",
      "+--------------+--------------------+--------------------+--------------------+\n",
      "|            -1|I had big expecta...|[i, had, big, exp...|[-0.0370439446113...|\n",
      "|             1|I highly recommen...|[i, highly, recom...|[0.00302896804805...|\n",
      "|            -1|This one is a rea...|[this, one, is, a...|[0.00766816143340...|\n",
      "|             1|Mysteries are int...|[mysteries, are, ...|[0.02922427154819...|\n",
      "|             1|This show always ...|[this, show, alwa...|[-0.0129554296898...|\n",
      "|             1|I discovered this...|[i, discovered, t...|[0.00260004208480...|\n",
      "|            -1|It beats watching...|[it, beats, watch...|[-0.0328859328292...|\n",
      "|            -1|There are many ep...|[there, are, many...|[-0.0305897704939...|\n",
      "|             1|This is the best ...|[this, is, the, b...|[-0.0207668397751...|\n",
      "|            -1|Not bad.  Didn't ...|[not, bad., , did...|[0.00248196386490...|\n",
      "+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2vdf.select(\"overall_recode\", \"reviewText\", \"tokenized_text\", \"w2v_vector\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have everything in numeric format, let's start with our old standby, the __random forest__. You can choose other classifiers to see how they perform, and even chain them together and use their collective predictions in an ensemble to improve model performance.\n",
    "\n",
    "Important - note that your data is now in the `w2vdf` object - not the `amznInstantVideo` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StringIndexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89bc613a58d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build the training indexers/split data/classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# first we'll generate a labelIndexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabelIndexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"overall_recode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexedLabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2vdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# now generate the indexed feature vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StringIndexer' is not defined"
     ]
    }
   ],
   "source": [
    "# Build the training indexers/split data/classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"overall_recode\", outputCol=\"indexedLabel\").fit(w2vdf)\n",
    "\n",
    "# now generate the indexed feature vector.\n",
    "featureIndexer = VectorIndexer(inputCol=\"w2v_vector\", outputCol=\"indexedFeatures\", maxCategories=4).fit(w2vdf)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = w2vdf.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.209119\n",
      "Accuracy = 0.790881\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't do so well... but that's typical in data science work.\n",
    "\n",
    "Here's where you can go from here:\n",
    "1. Think about resampling the overall dataset to better balance positive and negative reviews.\n",
    "2. Use a different method to tokenize and convert the text to numeric (TF/IDF, etc).\n",
    "3. Adjust the parameters of your classifier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
